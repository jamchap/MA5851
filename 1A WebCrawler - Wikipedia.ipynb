{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9a36725",
   "metadata": {},
   "source": [
    "# Web Scraping Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c671a765",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10dbc62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wikipedia_scrape(url_lookup, col_lst, n = 1):\n",
    "    \"\"\"\n",
    "    Custom function to perform the web scraping of Wikipedia\n",
    "    :param url_lookup: url string to web scrape\n",
    "    :param col_lst: list of column names for returned Data Frame\n",
    "    :param n: table 1 on the web page to scrape\n",
    "    :return: Pandas DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    # Scrape table data from URL\n",
    "    html_content = requests.get(url_lookup).text\n",
    "    soup = bs4.BeautifulSoup(html_content, \"lxml\")\n",
    "    table = soup.find_all('table')\n",
    "\n",
    "    # Find table elements\n",
    "    data = []\n",
    "    for child_table in soup.find_all('table'):\n",
    "        table_rows = child_table.findAll('tr')\n",
    "\n",
    "        # Add to list\n",
    "        data.append([[td.findChildren(text=True) for td in tr.findAll(\"td\")] for tr in table_rows])\n",
    "\n",
    "    # Create dataframe\n",
    "    df = pd.DataFrame()\n",
    "    for i in data[n]:\n",
    "        df = df.append(pd.DataFrame(i).transpose())\n",
    "    df.columns = col_lst\n",
    "    df.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    # Remove rows if film name is null\n",
    "    try:\n",
    "        df = df.loc[~(pd.isna(df['Film']) & (df['Film'] == '\\n')), :]\n",
    "        df = df.loc[~pd.isna(df['Year']), :]\n",
    "        df.reset_index(inplace=True, drop=True)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Correct Year using forward fill if filled with movie name\n",
    "    df['Year'] = df['Year'].apply(lambda x: re.sub(\"[^0-9]\", '', x))\n",
    "    df['Year'] = df['Year'].str.strip().dropna().apply(lambda x: np.NaN if len(x) == 0 else x)\n",
    "    df['Year'] = df['Year'].fillna(method='ffill')\n",
    "    \n",
    "    # Return only columns of interest\n",
    "    try:      \n",
    "        df = df.loc[:, ['Year', 'Film', 'Worldwide Gross']]\n",
    "    except KeyError: # if Worldwide Gross does not exist\n",
    "        df['Worldwide Gross'] = None\n",
    "        df = df.loc[:, ['Year', 'Film', 'Worldwide Gross']]\n",
    "    \n",
    "    # Remove new line\n",
    "    df['Year'] = df['Year'].str.strip()\n",
    "    df['Worldwide Gross'] = df['Worldwide Gross'].str.strip()\n",
    "    df['Film'] = df['Film'].str.strip()\n",
    "\n",
    "    # Return dataframe\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6dbc83",
   "metadata": {},
   "source": [
    "Dictionary of URLs to webscrape and column names to apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d041fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of URLs to scrape from Wikipedia\n",
    "wiki_dict = (\n",
    "    {'Sport': ['https://en.wikipedia.org/wiki/List_of_highest-grossing_sports_films'\n",
    "               , ['Film', 'Year', 'Worldwide Gross', 'Ref', 'Sport']\n",
    "               , 1]\n",
    "    ,'Superhero': ['https://en.wikipedia.org/wiki/List_of_highest-grossing_superhero_films'\n",
    "                   , ['Rank', 'Film', 'Worldwide Gross', 'Year', 'Superheroes', 'Source', 'Ref']\n",
    "                   , 0]\n",
    "    ,'Sci-fi': ['https://en.wikipedia.org/wiki/List_of_highest-grossing_science_fiction_films'\n",
    "                , ['Rank', 'Film', 'Worldwide Gross', 'Year', 'Ref']\n",
    "                , 1]\n",
    "    ,'Musical': ['https://en.wikipedia.org/wiki/List_of_highest-grossing_musicals#Highest-grossing_musical_films'\n",
    "                 , ['Rank', 'Film', 'Worldwide Gross', 'Year', 'Ref']\n",
    "                 , 1]\n",
    "    ,'Horror': ['https://en.wikipedia.org/wiki/List_of_highest-grossing_horror_films'\n",
    "                , ['Rank', 'Film', 'Worldwide Gross', 'Year', 'Franchise', 'Ref']\n",
    "                , 0]\n",
    "    ,'Fantasy': ['https://en.wikipedia.org/wiki/List_of_highest-grossing_fantasy_films'\n",
    "                , ['Rank', 'Film', 'Worldwide Gross', 'Year', 'Ref']\n",
    "                , 0]\n",
    "    ,'Comedy': ['https://en.wikipedia.org/wiki/List_of_highest-grossing_comedy_films'\n",
    "                , ['Rank', 'Film', 'Type', 'Worldwide Gross', 'Year', 'Ref']\n",
    "                , 0]\n",
    "    ,'Christmas': ['https://en.wikipedia.org/wiki/List_of_highest-grossing_Christmas_films'\n",
    "                   , ['Rank', 'Film', 'Worldwide Gross', 'Year', 'Ref']\n",
    "                   , 1]\n",
    "    ,'Openings': ['https://en.wikipedia.org/wiki/List_of_highest-grossing_openings_for_films'\n",
    "                 , ['Rank', 'Film', 'Year', 'Worldwide Gross']\n",
    "                 , 0]\n",
    "    ,'Puppet':  ['https://en.wikipedia.org/wiki/List_of_highest-grossing_puppet_films'\n",
    "               , ['Rank', 'Film', 'Worldwide Gross', 'Year', 'Ref']\n",
    "               , 0]\n",
    "    ,'Anime':  ['https://en.wikipedia.org/wiki/List_of_highest-grossing_anime_films'\n",
    "               , ['Rank', 'Film', 'Worldwide Gross', 'Year', 'Ref']\n",
    "               , 0]\n",
    "    ,'Box Office': ['https://en.wikipedia.org/wiki/List_of_films_by_box_office_admissions',\n",
    "                   [ 'Film', 'Year', 'Worldwide Gross','Territories', 'Notes']\n",
    "                   , 0]\n",
    "    ,'Worst': ['https://en.wikipedia.org/wiki/List_of_films_with_a_0%25_rating_on_Rotten_Tomatoes'\n",
    "              , [ 'Film', 'Year', '# reviews','Reference']\n",
    "              , 0]\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1caa9b2a",
   "metadata": {},
   "source": [
    "Run the WebCrawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59dc6a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines fetched for Sport: 50\n",
      "Lines fetched for Superhero: 50\n",
      "Lines fetched for Sci-fi: 49\n",
      "Lines fetched for Musical: 28\n",
      "Lines fetched for Horror: 50\n",
      "Lines fetched for Fantasy: 50\n",
      "Lines fetched for Comedy: 50\n",
      "Lines fetched for Christmas: 32\n",
      "Lines fetched for Openings: 50\n",
      "Lines fetched for Puppet: 22\n",
      "Lines fetched for Anime: 50\n",
      "Lines fetched for Box Office: 110\n",
      "Lines fetched for Worst: 41\n"
     ]
    }
   ],
   "source": [
    "# List to store results of WebCrawler\n",
    "lst_wiki = []\n",
    "\n",
    "# Loop through the URL dictionary\n",
    "for key, value in wiki_dict.items():\n",
    "    \n",
    "    # Values for WebCrawler\n",
    "    url = wiki_dict[key][0]\n",
    "    cols = wiki_dict[key][1]\n",
    "    n = wiki_dict[key][2]\n",
    "    \n",
    "    # Execute WebCrawler and save results in list\n",
    "    df = wikipedia_scrape(url, cols, n)\n",
    "    lst_wiki.append(df)\n",
    "\n",
    "    print(f'Lines fetched for {key}: {len(df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abaa2926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "617 films extracted from Wikipedia excluding duplicates\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Title</th>\n",
       "      <th>Worldwide Gross</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>The Hunger Games: Catching Fire</td>\n",
       "      <td>$865,011,746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014</td>\n",
       "      <td>The Hunger Games: Mockingjay – Part 1</td>\n",
       "      <td>$755,356,711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012</td>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>$694,394,724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1994</td>\n",
       "      <td>Forrest Gump</td>\n",
       "      <td>$678,222,284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015</td>\n",
       "      <td>The Hunger Games: Mockingjay – Part 2</td>\n",
       "      <td>$653,428,261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year                                  Title Worldwide Gross\n",
       "0  2013        The Hunger Games: Catching Fire    $865,011,746\n",
       "1  2014  The Hunger Games: Mockingjay – Part 1    $755,356,711\n",
       "2  2012                       The Hunger Games    $694,394,724\n",
       "3  1994                           Forrest Gump    $678,222,284\n",
       "4  2015  The Hunger Games: Mockingjay – Part 2    $653,428,261"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform data into a dataframe for future use\n",
    "df_concat = pd.concat(lst_wiki)\n",
    "df_concat.rename(columns={\"Film\": \"Title\"}, inplace=True)\n",
    "df_concat.drop_duplicates(inplace = True)\n",
    "df_concat.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# Backup list\n",
    "df_concat.to_csv('bk_wiki.csv', index = False)\n",
    "\n",
    "# Number of Films (excluding duplicates)\n",
    "print(f'{len(df_concat)} films extracted from Wikipedia excluding duplicates')\n",
    "\n",
    "df_concat.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
